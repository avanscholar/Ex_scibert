{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries and installing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#avoid all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the randomness\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the NLP library and dowmload the stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading csv file of XML parsed ~6000 DOIs. <path> contains the file\n",
    "df = pd.read_csv(r'C:\\Users\\Admin\\OneDrive - IIT Delhi\\CPCB\\PROF. HARI\\Jupyter_file\\Ex_scibert\\Abstract\\final_abstract.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#44 missing values are dropped. Total of 5901 abstracts are processed\n",
    "df.isnull().sum() #44 missing null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ChemDataExtractor doesn't detect lowered text for catalysts/ molecular compounds. \n",
    "But lemmatization, stopword removal and punctuation removal are done prior to catalyst detection** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning\n",
    "def clean(df, column):\n",
    "    df[column] = df[column].str.replace('[^\\w\\s]',' ') #Removes any kind of punctuation\n",
    "    df[column] = df[column].str.lstrip() #Strips of spaces from left and right ends of the abstract\n",
    "    df[column] = df[column].str.rstrip()\n",
    "    \n",
    "#Stopword Removal\n",
    "stop = stopwords.words('english')\n",
    "def stop_remover(dfc, column):\n",
    "    dfc[column] = dfc[column].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "#Lemmatization\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w,'v') for w in w_tokenizer.tokenize(text)]\n",
    "    \n",
    "clean(df, 'Abstract') #Text is cleaned for punctuation and spaces\n",
    "clean(df, 'Title')\n",
    "\n",
    "stop_remover(df, 'Abstract') #Stopwords are removed\n",
    "stop_remover(df, 'Title')\n",
    "\n",
    "df['Abstract_lemm'] = df['Abstract'].apply(lemmatize_text).apply(lambda x: \" \".join(x)) #All the words are lemmatized to avaoing confusion 'alcohol' & 'alcohols'\n",
    "df['Title_lemm'] = df['Title'].apply(lemmatize_text).apply(lambda x: \" \".join(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChemDataExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library imported\n",
    "from chemdataextractor import Document\n",
    "import chemdataextractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Compounds'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passing a text\n",
    "for i in range(5901):\n",
    "    doc = Document(df['Abstract'][i])\n",
    "    array = np.array(doc.cems)\n",
    "    listToStr = ' '.join([str(elem) for elem in array])\n",
    "    comp_array = np.array(listToStr)\n",
    "    s = comp_array.tolist().split()        \n",
    "    s = list(set(s))\n",
    "    listToStr2 = ' '.join([str(elem) for elem in s])\n",
    "    df['Compounds'][i] = listToStr2\n",
    "#Chemical entity mention\n",
    "df['Compounds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Joining all the processed lines together. Whole PDF\n",
    "long_string = ','.join([str(i) for i in list(df['Compounds'].values)])\n",
    "\n",
    "# WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\", \n",
    "                      max_words=100000, \n",
    "                      contour_width=5, \n",
    "                      contour_color='steelblue',\n",
    "                      repeat = False,\n",
    "                      relative_scaling = 0.5,\n",
    "                      min_font_size=3,\n",
    "                      max_font_size = 40)\n",
    "wordcloud.generate(long_string)\n",
    "\n",
    "# Visualizing\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatized abstract is converted to lower case\n",
    "df['Abstract_lemm'] = df['Abstract_lemm'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Reference 1](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/)\n",
    "* [Reference 2](https://towardsdatascience.com/evaluate-topic-model-in-python-latent-dirichlet-allocation-lda-7d57484bb5d0)\n",
    "* [Reference 3](https://towardsdatascience.com/topic-modeling-with-latent-dirichlet-allocation-e7ff75290f8)\n",
    "* [Reference 4](http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize words and further clean-up text\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  \n",
    "        \n",
    "data = df['Abstract_lemm'].tolist()\n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "\n",
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for Base model LDA with default alpha and beta values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=10, \n",
    "                                       random_state=100,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coherence Score is a measure for performance of LDA. LDA model is run mutliple times in a loop to maximize the coherence score for hyperparameters number of topics, alpha and beta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "beta.append('symmetric')\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n",
    "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
    "               gensim.utils.ClippedCorpus(corpus, int(num_of_docs*0.75)), \n",
    "               corpus]\n",
    "\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=540)\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
    "                                                  k=k, a=a, b=b)\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = pd.read_csv(r'C:\\Users\\Admin\\OneDrive - IIT Delhi\\CPCB\\PROF. HARI\\Jupyter_file\\Ex_scibert\\Abstract\\lda_tuning_results.csv')\n",
    "a1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.DataFrame()\n",
    "dd  = a1.loc[(a1.Alpha == '0.61') & (a1.Beta == '0.31') & (a1.Validation_Set == '75% Corpus')]\n",
    "#dd = a1.loc[a1.Topics == 9]\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.Coherence.nlargest(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1.loc[221]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = dd['Topics']\n",
    "y = dd['Coherence']\n",
    "\n",
    "plt.figure(figsize = (16, 12), linewidth = 20)\n",
    "plt.plot(x, y, c='r', linewidth=5)\n",
    "plt.scatter(a1['Topics'], a1['Coherence'], linewidths=4)\n",
    "plt.xlabel('Topics', fontweight='bold', fontsize=32)\n",
    "plt.ylabel('Coherence Score', fontweight='bold', fontsize=32)\n",
    "plt.xticks(fontweight='bold', fontsize=26)\n",
    "plt.yticks(fontweight='bold', fontsize=26)\n",
    "#plt.title('LDA: Topics vs Coherence Score (alpha=0.61, beta=0.61)', fontweight='bold', fontsize=28)\n",
    "plt.savefig(r'C:\\Users\\Admin\\OneDrive - IIT Delhi\\CPCB\\PROF. HARI\\data_final\\coherence.pdf', dpi=5000)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_Coherence = a1.Coherence.max()\n",
    "maxValueIndex = a1.Coherence.idxmax()\n",
    "print(maximum_Coherence, maxValueIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1.loc[222]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "random.seed(0)\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=9, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.61,\n",
    "                                           eta=0.31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most dominant topic for each document\n",
    "doc_lda = lda_model[corpus]\n",
    "\n",
    "corpus_topics = [sorted(topics, key=lambda record: -record[1])[0] for topics in doc_lda]\n",
    "topics = [[(term, round(wt, 3)) for term, wt in lda_model.show_topic(n, topn=10)] for n in range(0, lda_model.num_topics)]\n",
    "\n",
    "topics_df = pd.DataFrame([[term for term, wt in topic] for topic in topics], columns = ['Term'+str(i) for i in range(1, 11)], index=['Topic '+str(t) for t in range(1, lda_model.num_topics+1)]).T\n",
    "topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column width\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "topics_df = pd.DataFrame([', '.join([term for term, wt in topic]) for topic in topics], columns = ['Terms per Topic'], index=['Topic'+str(t) for t in range(1, lda_model.num_topics+1)] )\n",
    "topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df.columns, topics_df['Terms per Topic'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing with word clouds\n",
    "from wordcloud import WordCloud\n",
    "#wordcloud object\n",
    "wc = WordCloud(background_color=\"white\", colormap=\"Dark2\", max_font_size=150, random_state=42)\n",
    "\n",
    "#figure size\n",
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "\n",
    "#subplots for each topic\n",
    "for i in range(9):\n",
    "\n",
    "    wc.generate(text=topics_df[\"Terms per Topic\"][i])\n",
    "    \n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(topics_df.index[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_lemmatized)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic.Dominant_Topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df.columns, topics_df['Terms per Topic'][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dominant_topic.Dominant_Topic.value_counts().plot(kind='bar', rot=0, figsize = (16, 12), linewidth = 20)\n",
    "plt.xlabel(\"Topic Number\", labelpad=14, fontweight='bold', fontsize=35)\n",
    "plt.ylabel(\"Number of Documents\", labelpad=14, fontweight='bold', fontsize=35)\n",
    "plt.xticks(fontweight='bold', fontsize=26)\n",
    "plt.yticks(fontweight='bold', fontsize=26)\n",
    "#plt.savefig(r'C:\\Users\\Admin\\OneDrive - IIT Delhi\\CPCB\\PROF. HARI\\data_final\\bar_plot.pdf', dpi=5000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display setting to show more characters in column\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display setting to show more characters in column\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=False).head(1)], axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#most dominant topic for each document\n",
    "doc_lda = lda_model[corpus]\n",
    "\n",
    "corpus_topics = [sorted(topics, key=lambda record: -record[1])[0] for topics in doc_lda]\n",
    "topics = [[(term, round(wt, 3)) for term, wt in lda_model.show_topic(n, topn=50)] for n in range(0, lda_model.num_topics)]\n",
    "\n",
    "topics_df = pd.DataFrame([[term for term, wt in topic] for topic in topics], columns = ['Term'+str(i) for i in range(1, 51)], index=['Topic '+str(t) for t in range(1, lda_model.num_topics+1)]).T\n",
    "topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column width\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "topics_df = pd.DataFrame([', '.join([term for term, wt in topic]) for topic in topics], columns = ['Terms per Topic'], index=['Topic'+str(t) for t in range(1, lda_model.num_topics+1)] )\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Joining all the processed lines together. Whole PDF\n",
    "long_string = ','.join([str(i) for i in list(topics_df['Terms per Topic'][3])])\n",
    "# WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\",\n",
    "                      max_words=100000, \n",
    "                      contour_width=5, \n",
    "                      contour_color='steelblue',\n",
    "                      repeat = False,\n",
    "                      relative_scaling = 0.5,\n",
    "                      min_font_size=10,\n",
    "                      max_font_size = 250,\n",
    "                      width=1600,\n",
    "                      height=600)\n",
    "wordcloud.generate(text=topics_df[\"Terms per Topic\"][7].upper())\n",
    "\n",
    "# Visualizing\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Joining all the processed lines together. Whole PDF\n",
    "long_string = ','.join([str(i) for i in list(topics_df['Terms per Topic'][4])])\n",
    "# WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\",\n",
    "                      max_words=100000, \n",
    "                      contour_width=5, \n",
    "                      contour_color='steelblue',\n",
    "                      repeat = False,\n",
    "                      relative_scaling = 0.5,\n",
    "                      min_font_size=10,\n",
    "                      max_font_size = 250,\n",
    "                      width=1600,\n",
    "                      height=600)\n",
    "wordcloud.generate(text=topics_df[\"Terms per Topic\"][1].upper())\n",
    "\n",
    "# Visualizing\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing with word clouds\n",
    "from wordcloud import WordCloud\n",
    "#wordcloud object\n",
    "wc = WordCloud(background_color=\"white\", colormap=\"Dark2\", max_font_size=150, random_state=42)\n",
    "\n",
    "#figure size\n",
    "plt.rcParams['figure.figsize'] = [20, 15]\n",
    "\n",
    "#subplots for each topic\n",
    "for i in range(9):\n",
    "\n",
    "    wc.generate(text=topics_df[\"Terms per Topic\"][i])\n",
    "    \n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(topics_df.index[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get topic weights and dominant topics\n",
    "from sklearn.manifold import TSNE\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.models import Label\n",
    "from bokeh.io import output_notebook\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from matplotlib import rc\n",
    "\n",
    "# Get topic weights\n",
    "# topic_weights = []\n",
    "# for i, row_list in enumerate(lda_model[corpus]):\n",
    "#     topic_weights.append([w for i, w in row_list[0]])\n",
    "    \n",
    "# n-1 rows each is a vector with i-1 posisitons, where n the number of documents\n",
    "# i the topic number and tmp[i] = probability of topic i\n",
    "topic_weights = []\n",
    "for row_list in lda_model[corpus]:\n",
    "    tmp = np.zeros(9)\n",
    "    for i, w in row_list:\n",
    "        tmp[i] = w\n",
    "        topic_weights.append(tmp)\n",
    "arr = pd.DataFrame(topic_weights).fillna(0).values\n",
    "\n",
    "\n",
    "# Array of topic weights    \n",
    "arr = pd.DataFrame(topic_weights).fillna(0).values\n",
    "\n",
    "# Keep the well separated points (optional)\n",
    "arr = arr[np.amax(arr, axis=1) > 0.35]\n",
    "\n",
    "# Dominant topic number in each doc\n",
    "topic_num = np.argmax(arr, axis=1)\n",
    "\n",
    "# tSNE Dimension Reduction\n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')\n",
    "tsne_lda = tsne_model.fit_transform(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_num_ = pd.Series(topic_num)\n",
    "df = pd.DataFrame(tsne_lda)\n",
    "df.columns = ['tsne_0', 'tsne_1']\n",
    "df['label'] = topic_num_ \n",
    "\n",
    "unique = list(set(df['label']))\n",
    "\n",
    "colors = [plt.cm.jet(float(i)/max(unique)) for i in unique]\n",
    "\n",
    "plt.figure(figsize=(13,13))\n",
    "for i, u in enumerate(unique):\n",
    "    xi = [df['tsne_0'][j] for j  in range(len(df['tsne_0'])) if df['label'][j] == u]\n",
    "    yi = [df['tsne_1'][j] for j  in range(len(df['tsne_1'])) if df['label'][j] == u]\n",
    "    plt.scatter(xi, y=yi, c=colors[i], label='Topic_'+str(u))\n",
    "\n",
    "plt.xlabel('t_SNE_1',fontweight='bold', fontsize= 24)\n",
    "plt.ylabel('t_SNE_2',fontweight='bold', fontsize=24)\n",
    "\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "\n",
    "plt.tick_params(axis=\"x\", direction=\"in\",width=2)\n",
    "plt.tick_params(axis=\"y\", direction=\"in\", width=2)\n",
    "\n",
    "rc('font', weight='bold')\n",
    "\n",
    "plt.tick_params(bottom=True, top=True, left=True, right=True)\n",
    "plt.tick_params(labelbottom=True, labeltop=False, labelleft=True, labelright=False)\n",
    "\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "\n",
    "plt.legend(frameon=False,prop={'weight':'bold',\"size\":15})\n",
    "\n",
    "plt.savefig(r'C:\\Users\\Admin\\OneDrive - IIT Delhi\\CPCB\\PROF. HARI\\paper\\pipeline\\tsne.pdf', dpi=5000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
