{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://github.com/ElsevierDev/elsapy/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xml.etree.ElementTree â€” The ElementTree XML API\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import some basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some important elsevier api libraries\n",
    "from elsapy.elsclient import ElsClient\n",
    "from elsapy.elsprofile import ElsAuthor, ElsAffil\n",
    "from elsapy.elsdoc import FullDoc, AbsDoc\n",
    "from elsapy.elssearch import ElsSearch\n",
    "import json\n",
    "import csv\n",
    "import requests\n",
    "import xmltodict\n",
    "import urllib3\n",
    "import re\n",
    "\n",
    "#Import warnings library\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = {'apikey': '22d18e0c4fdc59bb8898844056b2be57'}\n",
    "config = {\n",
    "    \"apikey\": \"Enter your API key\",\n",
    " \"insttoken\": \"Enter your institute token\"\n",
    "    }\n",
    "\n",
    "client = ElsClient(config['apikey'])\n",
    "client.inst_token = config['insttoken']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Science Direct Full Text API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data loaded here with links\n",
    "df = pd.read_csv(r'C:\\Users\\Admin\\OneDrive - IIT Delhi\\CPCB\\PROF. HARI\\doi_6000_withlink.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random check the links** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a header's dictionary to pass through requests\n",
    "headers_dict = {\"X-ELS-APIKey\": config['apikey'], \"X-ELS-Insttoken\": config['insttoken'], \"Accept\": \"application/xml\"}\n",
    "\n",
    "yes = 0\n",
    "no = 0\n",
    "for i in range(0, df.shape[0]):\n",
    "    #x takes response of the HTTP request, passes link\n",
    "    x = requests.get(df['Link'][i], headers=headers_dict)\n",
    "    #print(x.text) #check\n",
    "        \n",
    "    #saving it as XML file\n",
    "    with open(\"full_text.xml\", 'wb') as f:\n",
    "        f.write(x.content)\n",
    "        \n",
    "    tree = ET.parse(r'C:\\Users\\Admin\\OneDrive - IIT Delhi\\CPCB\\PROF. HARI\\full_text.xml')\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    original_text = root.find('{http://www.elsevier.com/xml/svapi/article/dtd}originalText')\n",
    "    doc = original_text.find('{http://www.elsevier.com/xml/xocs/dtd}doc')\n",
    "    serial_item = doc.find('{http://www.elsevier.com/xml/xocs/dtd}serial-item')\n",
    "    print(serial_item)\n",
    "\n",
    "    if serial_item != None:\n",
    "        yes +=1\n",
    "        print(yes)\n",
    "    else:\n",
    "        #print(\"Full text for this paper doesn't exist\")\n",
    "        no+=1\n",
    "        \n",
    "print(yes)\n",
    "print(no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to Extract Coredata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coredata is present in every paper\n",
    "\n",
    "#Element.findall() finds only elements with a tag which are direct children of the current element\n",
    "#Element.find() finds the first child with a particular tag\n",
    "\n",
    "#defining a header's dictionary to pass through requests\n",
    "headers_dict = {\"X-ELS-APIKey\": config['apikey'], \"X-ELS-Insttoken\": config['insttoken'], \"Accept\": \"application/xml\"}\n",
    "\n",
    "#x takes response of the HTTP request, random passes link\n",
    "x = requests.get(df['Link'][3], headers=headers_dict)\n",
    "#print(x.text) #check\n",
    "    \n",
    "#saving it as XML file\n",
    "with open(\"full_text.xml\", 'wb') as f:\n",
    "    f.write(x.content)\n",
    "\n",
    "#Reading the data\n",
    "#<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "tree = ET.parse(r'C:\\Users\\Admin\\OneDrive - IIT Delhi\\CPCB\\PROF. HARI\\full_text.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "for entry in root.findall('{http://www.elsevier.com/xml/svapi/article/dtd}coredata'):\n",
    "    \n",
    "    url = []; doi =[]; title = []; pub_name =[]; type_ = []\n",
    "    description = []\n",
    "    #CHECK CODE\n",
    "    url.append(entry.find('{http://prismstandard.org/namespaces/basic/2.0/}url').text)\n",
    "    doi.append(entry.find('{http://prismstandard.org/namespaces/basic/2.0/}doi').text)\n",
    "    title.append(entry.find('{http://purl.org/dc/elements/1.1/}title').text)\n",
    "    pub_name.append(entry.find('{http://prismstandard.org/namespaces/basic/2.0/}publicationName').text)\n",
    "    type_.append(entry.find('{http://prismstandard.org/namespaces/basic/2.0/}aggregationType').text)\n",
    "    description.append(entry.find('{http://purl.org/dc/elements/1.1/}description').text)\n",
    "    description[0] = \" \".join(description[0].split())\n",
    "    print('URL:',url )\n",
    "    print('DOI:', doi)\n",
    "    print('Title:', title)\n",
    "    print('Journal name:',pub_name )\n",
    "    print('Type:',type_ )\n",
    "    print('\\n')\n",
    "    print('Abstract:',description[0] )\n",
    "    print('\\n')\n",
    "    \n",
    "#Extract the list of authors and keywords mentioned      \n",
    "original_text = root.find('{http://www.elsevier.com/xml/svapi/article/dtd}originalText')\n",
    "#print(originaltext)\n",
    "doc = original_text.find('{http://www.elsevier.com/xml/xocs/dtd}doc')\n",
    "#print(doc)\n",
    "serial_item = doc.find('{http://www.elsevier.com/xml/xocs/dtd}serial-item')\n",
    "#print(serial_item)\n",
    "\n",
    "keyword_list = []\n",
    "author_list = []\n",
    "if serial_item != None:\n",
    "    article = serial_item.find('{http://www.elsevier.com/xml/ja/dtd}article')\n",
    "    #print(article)\n",
    "    head = article.find('{http://www.elsevier.com/xml/ja/dtd}head')\n",
    "    #print(head)\n",
    "    author_group = head.find('{http://www.elsevier.com/xml/common/dtd}author-group')\n",
    "    #print(author_group)\n",
    "\n",
    "    keywords_ = head.find('{http://www.elsevier.com/xml/common/dtd}keywords')\n",
    "    #print(keywords_)\n",
    "\n",
    "    for author in author_group.findall('{http://www.elsevier.com/xml/common/dtd}author'):\n",
    "        name = author.find('{http://www.elsevier.com/xml/common/dtd}given-name').text\n",
    "        surname = author.find('{http://www.elsevier.com/xml/common/dtd}surname').text\n",
    "        author_list.append(name + ' ' + surname)\n",
    "        #print('\\n')\n",
    "\n",
    "    for word in keywords_.itertext():\n",
    "        keyword_list.append(word)\n",
    "\n",
    "    keyword_list = \"\".join(keyword_list)\n",
    "    keyword_list = list(keyword_list.split())\n",
    "    #keywords, authors present in the paper\n",
    "    print('Keywords present:',keyword_list)\n",
    "    print('Authors: ',author_list)\n",
    "else:\n",
    "    print(\"Full text for this paper doesn't exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to extract full text and store in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a header's dictionary to pass through requests\n",
    "headers_dict = {\"X-ELS-APIKey\": \"Enter your API key\", \"X-ELS-Insttoken\": \"Enter your institute token\", \"Accept\": \"application/xml\"}\n",
    "df_temp = pd.DataFrame()\n",
    "excel_writer = pd.ExcelWriter(r'C:\\Users\\Admin\\OneDrive - IIT Delhi\\CPCB\\PROF. HARI\\test2.xlsx', engine='xlsxwriter')\n",
    "for i in np.arange(0,2,1):\n",
    "    print(i, 'done' )\n",
    "    #x takes response of the HTTP request, passes link\n",
    "    x = requests.get(df['Link'][i], headers=headers_dict)\n",
    "\n",
    "    #saving it as XML file\n",
    "    with open(\"full_text.xml\", 'wb') as f:\n",
    "        f.write(x.content)\n",
    "\n",
    "    #Reading the data\n",
    "    #<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "    tree = ET.parse(r'C:\\Users\\Admin\\OneDrive - IIT Delhi\\CPCB\\PROF. HARI\\full_text.xml')\n",
    "    root = tree.getroot()\n",
    "    original_text = root.find('{http://www.elsevier.com/xml/svapi/article/dtd}originalText')\n",
    "    \n",
    "    if original_text != None:\n",
    "        doc = original_text.find('{http://www.elsevier.com/xml/xocs/dtd}doc')\n",
    "        serial_item = doc.find('{http://www.elsevier.com/xml/xocs/dtd}serial-item')\n",
    "\n",
    "        if serial_item != None:\n",
    "            article = serial_item.find('{http://www.elsevier.com/xml/ja/dtd}article')\n",
    "            \n",
    "            if article != None:\n",
    "                body = article.find('{http://www.elsevier.com/xml/ja/dtd}body')\n",
    "                \n",
    "                if body != None:\n",
    "                    sections = body.find('{http://www.elsevier.com/xml/common/dtd}sections')\n",
    "                    \n",
    "                    #lists for dataframe\n",
    "                    label_list = [] \n",
    "                    title_list = []\n",
    "                    para_list = []\n",
    "\n",
    "                    for section1 in sections.findall('{http://www.elsevier.com/xml/common/dtd}section'):\n",
    "                        if section1.find('{http://www.elsevier.com/xml/common/dtd}label') != None:\n",
    "                        #if section1 != None:\n",
    "                            label = section1.find('{http://www.elsevier.com/xml/common/dtd}label').text\n",
    "                            label_list.append(label)\n",
    "                            section_title_list = []\n",
    "                            section_title = section1.find('{http://www.elsevier.com/xml/common/dtd}section-title')\n",
    "                            for sec in section_title.itertext():\n",
    "                                section_title_list.append(sec)\n",
    "\n",
    "                            section_title_list = \"\".join(section_title_list)\n",
    "                            section_title_list = list(section_title_list.split()) \n",
    "                            section_title_list = \" \".join(section_title_list)\n",
    "                            title_list.append(section_title_list)\n",
    "                            print(section_title_list)\n",
    "\n",
    "                            total_para = []\n",
    "                            for paragraph in section1.findall('{http://www.elsevier.com/xml/common/dtd}para'):\n",
    "                                if paragraph != None:\n",
    "                                    paragraph1 = []\n",
    "                                    for p in paragraph.itertext():\n",
    "                                        paragraph1.append(p)\n",
    "\n",
    "                                    paragraph1 = \"\".join(paragraph1)\n",
    "                                    paragraph1 = list(paragraph1.split()) \n",
    "                                    paragraph1 = \" \".join(paragraph1)\n",
    "                                    total_para.append(paragraph1)\n",
    "\n",
    "                            total_para = \" \".join(total_para)\n",
    "                            #print(total_para)\n",
    "                            para_list.append(total_para)\n",
    "                            print('\\n')\n",
    "\n",
    "                            for section2 in section1.findall('{http://www.elsevier.com/xml/common/dtd}section'):\n",
    "                                if section2.find('{http://www.elsevier.com/xml/common/dtd}label') !=None:\n",
    "\n",
    "                                    label = section2.find('{http://www.elsevier.com/xml/common/dtd}label').text\n",
    "\n",
    "                                    label_list.append(label)\n",
    "                                    print('sub-section ', label)\n",
    "\n",
    "                                    sub_section_title_list = []\n",
    "\n",
    "                                    sub_section_title = section2.find('{http://www.elsevier.com/xml/common/dtd}section-title')\n",
    "                                    for sub in sub_section_title.itertext():\n",
    "                                        sub_section_title_list.append(sub)\n",
    "\n",
    "                                    sub_section_title_list = \"\".join(sub_section_title_list)\n",
    "                                    sub_section_title_list = list(sub_section_title_list.split()) \n",
    "                                    sub_section_title_list = \" \".join(sub_section_title_list)\n",
    "                                    title_list.append(sub_section_title_list)\n",
    "                                    #print('sub-section-title: ', sub_section_title_list)\n",
    "\n",
    "                                    para1 = []\n",
    "                                    for para in section2.itertext():\n",
    "                                    #findall('{http://www.elsevier.com/xml/common/dtd}para'):\n",
    "                                        #paragraph = para.\n",
    "                                        #for i in paragraph: \n",
    "                                        para1.append(para)\n",
    "\n",
    "                                    para1 = \"\".join(para1)\n",
    "                                    para1 = list(para1.split()) \n",
    "                                    para1 = \" \".join(para1)\n",
    "                                    #print(para1) \n",
    "                                    para_list.append(para1)\n",
    "                                    print('\\n')\n",
    "\n",
    "    temp = dict(doi = np.array(doi), \n",
    "         title = np.array(title), \n",
    "         pub_name = np.array(pub_name), \n",
    "         Type = np.array(type_), \n",
    "         abstract= np.array(description), \n",
    "         authors= np.array(author_list), \n",
    "         keyword =np.array(keyword_list),\n",
    "         title_label = np.array(label_list),\n",
    "         titles = np.array(title_list),\n",
    "         text = np.array(para_list))\n",
    "    \n",
    "    #print(len(temp['text']), type(temp['text']))\n",
    "    #print(len(temp['titles']), type(temp['titles']))\n",
    "    \n",
    "    df_temp = pd.DataFrame({'sections' : temp['titles'].tolist(), 'Text': temp['text'].tolist()})\n",
    "    \n",
    "    #df_temp.head()\n",
    "    \n",
    "    #Save each data frame\n",
    "    df_temp.to_csv(r'{}.csv'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "list_abstract = []\n",
    "list_doi= []\n",
    "list_title = []\n",
    "\n",
    "## ScienceDirect (full-text) document example using DOI\n",
    "#for i in range(len(data)):\n",
    "from pprint import pprint\n",
    "doi= df['DOI']\n",
    "for i in range(df.shape[0]):\n",
    "    pprint(doi[i])\n",
    "    doi_doc = FullDoc(doi = doi[i])\n",
    "    if doi_doc.read(client):\n",
    "\n",
    "        #pprint((doi_doc.title))\n",
    "        abstract = doi_doc._data['coredata']['dc:description']\n",
    "        title = doi_doc.title\n",
    "        #pprint(abstract)\n",
    "        print(i, 'done')\n",
    "        #dict_abstract['DOI'] = doi[i]\n",
    "        #dict_abstract['Abstract'] = abstract\n",
    "        list_abstract.append(abstract)\n",
    "        list_doi.append(doi[i])\n",
    "        list_title.append(title)\n",
    "        #doi_doc.write()\n",
    "\n",
    "    else:\n",
    "        pprint('Operation failed')\n",
    "        #dict_abstract['DOI'] = doi[i]\n",
    "        #dict_abstract['Abstract'] = 'NAN'\n",
    "        list_abstract.append('0')\n",
    "        list_doi.append('1')\n",
    "        list_title.append('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_available_abstract = pd.DataFrame()\n",
    "df_available_abstract['DOI'] = list_doi\n",
    "df_available_abstract['Title'] = list_title\n",
    "df_available_abstract['Abstract'] = list_abstract\n",
    "\n",
    "df_available_abstract.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_available_abstract.to_csv(r'C:\\Users\\Admin\\OneDrive - IIT Delhi\\CPCB\\PROF. HARI\\Jupyter_file\\Ex_scibert\\Abstract\\final_abstract.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
