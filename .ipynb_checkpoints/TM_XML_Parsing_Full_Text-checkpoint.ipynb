{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/ElsevierDev/elsapy/archive/master.zip\n",
      "  Downloading https://github.com/ElsevierDev/elsapy/archive/master.zip\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from elsapy==0.5.0) (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->elsapy==0.5.0) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests->elsapy==0.5.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->elsapy==0.5.0) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->elsapy==0.5.0) (2.10)\n"
     ]
    }
   ],
   "source": [
    "!pip install https://github.com/ElsevierDev/elsapy/archive/master.zip\n",
    "#Install necessary extensions/libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xml.etree.ElementTree â€” The ElementTree XML API\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "#Essential libraries\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#Essential libraries to make API requests with ElsSearch\n",
    "from elsapy.elsclient import ElsClient\n",
    "from elsapy.elsprofile import ElsAuthor, ElsAffil\n",
    "from elsapy.elsdoc import FullDoc, AbsDoc\n",
    "from elsapy.elssearch import ElsSearch\n",
    "import json\n",
    "import csv\n",
    "import pprint\n",
    "import requests\n",
    "import xmltodict\n",
    "import urllib3\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Science Direct Full Text API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Pub_Name</th>\n",
       "      <th>DOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://api.elsevier.com/content/article/pii/S...</td>\n",
       "      <td>Hydrogen and alcohols production by &lt;ce:italic...</td>\n",
       "      <td>Journal of CO2 Utilization</td>\n",
       "      <td>10.1016/j.jcou.2022.101914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://api.elsevier.com/content/article/pii/S...</td>\n",
       "      <td>Photocatalytic hydrogen production from alcoho...</td>\n",
       "      <td>Journal of Photochemistry and Photobiology A: ...</td>\n",
       "      <td>10.1016/j.jphotochem.2021.113726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://api.elsevier.com/content/article/pii/S...</td>\n",
       "      <td>Homogeneous first-row transition metal catalys...</td>\n",
       "      <td>Tetrahedron</td>\n",
       "      <td>10.1016/j.tet.2021.132473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://api.elsevier.com/content/article/pii/S...</td>\n",
       "      <td>Selective photoelectrocatalytic tuning of benz...</td>\n",
       "      <td>Applied Catalysis B: Environmental</td>\n",
       "      <td>10.1016/j.apcatb.2020.119868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://api.elsevier.com/content/article/pii/S...</td>\n",
       "      <td>Light alcohols reforming towards renewable hyd...</td>\n",
       "      <td>Renewable and Sustainable Energy Reviews</td>\n",
       "      <td>10.1016/j.rser.2020.110523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  \\\n",
       "0  https://api.elsevier.com/content/article/pii/S...   \n",
       "1  https://api.elsevier.com/content/article/pii/S...   \n",
       "2  https://api.elsevier.com/content/article/pii/S...   \n",
       "3  https://api.elsevier.com/content/article/pii/S...   \n",
       "4  https://api.elsevier.com/content/article/pii/S...   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Hydrogen and alcohols production by <ce:italic...   \n",
       "1  Photocatalytic hydrogen production from alcoho...   \n",
       "2  Homogeneous first-row transition metal catalys...   \n",
       "3  Selective photoelectrocatalytic tuning of benz...   \n",
       "4  Light alcohols reforming towards renewable hyd...   \n",
       "\n",
       "                                            Pub_Name  \\\n",
       "0                         Journal of CO2 Utilization   \n",
       "1  Journal of Photochemistry and Photobiology A: ...   \n",
       "2                                        Tetrahedron   \n",
       "3                 Applied Catalysis B: Environmental   \n",
       "4           Renewable and Sustainable Energy Reviews   \n",
       "\n",
       "                                DOI  \n",
       "0        10.1016/j.jcou.2022.101914  \n",
       "1  10.1016/j.jphotochem.2021.113726  \n",
       "2         10.1016/j.tet.2021.132473  \n",
       "3      10.1016/j.apcatb.2020.119868  \n",
       "4        10.1016/j.rser.2020.110523  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the doi file previously extracted from ElsSearch API\n",
    "#Our data is stored in <path>\n",
    "df = pd.read_csv(r'C:\\Users\\Admin\\OneDrive - IIT Delhi\\CPCB\\PROF. HARI\\Jupyter_file\\Ex_scibert\\doi_6000.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Institute Token for subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#Append \"apikey\" and \"insttoken\" as suggest in the ElsSearch document into a config file\n",
    "config = {\n",
    "    \"apikey\": \"2dc442325fc67f2f275ec3157ef8df65\",\n",
    " \"insttoken\": \"6beb1f6c29d85f50029bf11c8de94d1b\"\n",
    "    }\n",
    "\n",
    "client = ElsClient(config['apikey'])\n",
    "client.inst_token = config['insttoken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#Create string1 and string2 to join doi with institoken to make a single URL\n",
    "string1 = \"https://api.elsevier.com/content/article/doi/\" \n",
    "string2 = \"?apiKey=2dc442325fc67f2f275ec3157ef8df65&insttoken=6beb1f6c29d85f50029bf11c8de94d1b\"\n",
    "\n",
    "#Access every DOI in the previous file and append the new URL to another column\n",
    "df['Link'] = df['DOI'].apply(lambda x: string1 + str(x) + string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://api.elsevier.com/content/article/doi/10.1016/j.jcou.2022.101914?apiKey=2dc442325fc67f2f275ec3157ef8df65&insttoken=6beb1f6c29d85f50029bf11c8de94d1b'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of a Link for 1st DOI in the file\n",
    "df['Link'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#Save the combined abstracts in another CSV file\n",
    "df.to_csv(r'C:\\Users\\Admin\\OneDrive - IIT Delhi\\CPCB\\PROF. HARI\\Jupyter_file\\Ex_scibert\\doi_6000_withlink.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Pub_Name</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://api.elsevier.com/content/article/pii/S...</td>\n",
       "      <td>Hydrogen and alcohols production by &lt;ce:italic...</td>\n",
       "      <td>Journal of CO2 Utilization</td>\n",
       "      <td>10.1016/j.jcou.2022.101914</td>\n",
       "      <td>https://api.elsevier.com/content/article/doi/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://api.elsevier.com/content/article/pii/S...</td>\n",
       "      <td>Photocatalytic hydrogen production from alcoho...</td>\n",
       "      <td>Journal of Photochemistry and Photobiology A: ...</td>\n",
       "      <td>10.1016/j.jphotochem.2021.113726</td>\n",
       "      <td>https://api.elsevier.com/content/article/doi/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://api.elsevier.com/content/article/pii/S...</td>\n",
       "      <td>Homogeneous first-row transition metal catalys...</td>\n",
       "      <td>Tetrahedron</td>\n",
       "      <td>10.1016/j.tet.2021.132473</td>\n",
       "      <td>https://api.elsevier.com/content/article/doi/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://api.elsevier.com/content/article/pii/S...</td>\n",
       "      <td>Selective photoelectrocatalytic tuning of benz...</td>\n",
       "      <td>Applied Catalysis B: Environmental</td>\n",
       "      <td>10.1016/j.apcatb.2020.119868</td>\n",
       "      <td>https://api.elsevier.com/content/article/doi/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://api.elsevier.com/content/article/pii/S...</td>\n",
       "      <td>Light alcohols reforming towards renewable hyd...</td>\n",
       "      <td>Renewable and Sustainable Energy Reviews</td>\n",
       "      <td>10.1016/j.rser.2020.110523</td>\n",
       "      <td>https://api.elsevier.com/content/article/doi/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 URL  \\\n",
       "0  https://api.elsevier.com/content/article/pii/S...   \n",
       "1  https://api.elsevier.com/content/article/pii/S...   \n",
       "2  https://api.elsevier.com/content/article/pii/S...   \n",
       "3  https://api.elsevier.com/content/article/pii/S...   \n",
       "4  https://api.elsevier.com/content/article/pii/S...   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Hydrogen and alcohols production by <ce:italic...   \n",
       "1  Photocatalytic hydrogen production from alcoho...   \n",
       "2  Homogeneous first-row transition metal catalys...   \n",
       "3  Selective photoelectrocatalytic tuning of benz...   \n",
       "4  Light alcohols reforming towards renewable hyd...   \n",
       "\n",
       "                                            Pub_Name  \\\n",
       "0                         Journal of CO2 Utilization   \n",
       "1  Journal of Photochemistry and Photobiology A: ...   \n",
       "2                                        Tetrahedron   \n",
       "3                 Applied Catalysis B: Environmental   \n",
       "4           Renewable and Sustainable Energy Reviews   \n",
       "\n",
       "                                DOI  \\\n",
       "0        10.1016/j.jcou.2022.101914   \n",
       "1  10.1016/j.jphotochem.2021.113726   \n",
       "2         10.1016/j.tet.2021.132473   \n",
       "3      10.1016/j.apcatb.2020.119868   \n",
       "4        10.1016/j.rser.2020.110523   \n",
       "\n",
       "                                                Link  \n",
       "0  https://api.elsevier.com/content/article/doi/1...  \n",
       "1  https://api.elsevier.com/content/article/doi/1...  \n",
       "2  https://api.elsevier.com/content/article/doi/1...  \n",
       "3  https://api.elsevier.com/content/article/doi/1...  \n",
       "4  https://api.elsevier.com/content/article/doi/1...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.read_csv(r'C:\\Users\\Admin\\OneDrive - IIT Delhi\\CPCB\\PROF. HARI\\Jupyter_file\\Ex_scibert\\doi_6000_withlink.csv')\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A checkloop to extract the number of full-text papers returned based on previous API request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n"
     ]
    }
   ],
   "source": [
    "#Define a header's dictionary to pass through requests\n",
    "headers_dict = {\"X-ELS-APIKey\": \"2dc442325fc67f2f275ec3157ef8df65\", \"X-ELS-Insttoken\": \"6beb1f6c29d85f50029bf11c8de94d1b\", \"Accept\": \"application/xml\"}\n",
    "\n",
    "#Indicators for every file\n",
    "yes = 0\n",
    "no = 0\n",
    "\n",
    "#Loop to extract every file from the list of unique (5945) DOIs\n",
    "for i in range(0, 5945):\n",
    "    \n",
    "    #x takes response of the HTTP request, passes link\n",
    "    x = requests.get(df_new['Link'][i], headers=headers_dict)\n",
    "    #print(x.text) #check\n",
    "        \n",
    "    #Save response as XML file (stored in root path of the user)\n",
    "    with open(\"full_text.xml\", 'wb') as f:\n",
    "        f.write(x.content)\n",
    "    \n",
    "    #tree calls the XML file stored at root location\n",
    "    tree = ET.parse(r'C:\\Users\\Admin\\OneDrive - IIT Delhi\\CPCB\\PROF. HARI\\Jupyter_file\\Ex_scibert\\full_text.xml')\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    original_text = root.find('{http://www.elsevier.com/xml/svapi/article/dtd}originalText')\n",
    "    #print(originaltext)\n",
    "    doc = original_text.find('{http://www.elsevier.com/xml/xocs/dtd}doc')\n",
    "    #print(doc)\n",
    "    serial_item = doc.find('{http://www.elsevier.com/xml/xocs/dtd}serial-item')\n",
    "    #print(serial_item)\n",
    "\n",
    "    if serial_item != None:\n",
    "        yes +=1\n",
    "        print(yes)\n",
    "    else:\n",
    "        #print(\"Full text for this paper doesn't exist\")\n",
    "        no+=1\n",
    "        \n",
    "print(yes)\n",
    "print(no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a header's dictionary to pass through requests\n",
    "headers_dict = {\"X-ELS-APIKey\": \"2dc442325fc67f2f275ec3157ef8df65\", \"X-ELS-Insttoken\": \"6beb1f6c29d85f50029bf11c8de94d1b\", \"Accept\": \"application/xml\"}\n",
    "\n",
    "#x takes response of the HTTP request, passes link\n",
    "x = requests.get(df_new['Link'][15], headers=headers_dict)\n",
    "#print(x.text) #check\n",
    "    \n",
    "#Save response as XML file (stored in root path of the user)\n",
    "with open(\"full_text.xml\", 'wb') as f:\n",
    "    f.write(x.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['Link'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data\n",
    "\n",
    "#<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "\n",
    "#tree calls the XML file stored at root location\n",
    "tree = ET.parse(r'C:\\Users\\swath\\full_text.xml')\n",
    "root = tree.getroot()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The XML file Looks like this for DOI: 10.1016/j.tet.2021.132473\n",
    "\n",
    "# <full-text-retrieval-response xmlns=\"http://www.elsevier.com/xml/svapi/article/dtd\" \n",
    "#    xmlns:bk=\"http://www.elsevier.com/xml/bk/dtd\" xmlns:cals=\"http://www.elsevier.com/xml/common/cals/dtd\" \n",
    "#    xmlns:ce=\"http://www.elsevier.com/xml/common/dtd\" \n",
    "#    xmlns:ja=\"http://www.elsevier.com/xml/ja/dtd\" \n",
    "#    xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" \n",
    "#    xmlns:sa=\"http://www.elsevier.com/xml/common/struct-aff/dtd\" \n",
    "#    xmlns:sb=\"http://www.elsevier.com/xml/common/struct-bib/dtd\" \n",
    "#    xmlns:tb=\"http://www.elsevier.com/xml/common/table/dtd\" \n",
    "#    xmlns:xlink=\"http://www.w3.org/1999/xlink\" \n",
    "#    xmlns:xocs=\"http://www.elsevier.com/xml/xocs/dtd\" \n",
    "#    xmlns:dc=\"http://purl.org/dc/elements/1.1/\" \n",
    "#    xmlns:dcterms=\"http://purl.org/dc/terms/\" \n",
    "#    xmlns:prism=\"http://prismstandard.org/namespaces/basic/2.0/\" \n",
    "#    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\n",
    "# <coredata>\n",
    "# ... #This part has all basic info \n",
    "# </coredata>\n",
    "# <objects>\n",
    "# ... #This part is unnecessary\n",
    "# </objects>\n",
    "# <scopus-id>85116092071</scopus-id>\n",
    "# <scopus-eid>2-s2.0-85116092071</scopus-eid>\n",
    "# <link href=\"https://api.elsevier.com/content/abstract/scopus_id/85116092071\" rel=\"abstract\"/>\n",
    "# <originalText>\n",
    "# ... #This is the main part\n",
    "      #head\n",
    "            #title\n",
    "            #author\n",
    "            #abstract\n",
    "            #keywords\n",
    "      #body \n",
    "            #sections\n",
    "            #para\n",
    "                #subsections\n",
    "                    #para\n",
    "                \n",
    "      #tail (useless)\n",
    "# </originalText>\n",
    "# </full-text-retrieval-response>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to Extract Coredata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coredata is present in every paper\n",
    "\n",
    "#Element.findall() finds only elements with a tag which are direct children of the current element\n",
    "#Element.find() finds the first child with a particular tag\n",
    "\n",
    "#Manually entered XML with Namespaces\n",
    "#df = pd.DataFrame({'url': url, 'doi': doi, 'title': title, 'pub_name': pub_name, 'type': type_, 'abstract': description})\n",
    "\n",
    "for entry in root.findall('{http://www.elsevier.com/xml/svapi/article/dtd}coredata'):\n",
    "    \n",
    "    url = []; doi =[]; title = []; pub_name =[]; type_ = []\n",
    "    description = []\n",
    "    #CHECK CODE\n",
    "    url.append(entry.find('{http://prismstandard.org/namespaces/basic/2.0/}url').text)\n",
    "    doi.append(entry.find('{http://prismstandard.org/namespaces/basic/2.0/}doi').text)\n",
    "    title.append(entry.find('{http://purl.org/dc/elements/1.1/}title').text)\n",
    "    pub_name.append(entry.find('{http://prismstandard.org/namespaces/basic/2.0/}publicationName').text)\n",
    "    type_.append(entry.find('{http://prismstandard.org/namespaces/basic/2.0/}aggregationType').text)\n",
    "    description.append(entry.find('{http://purl.org/dc/elements/1.1/}description').text)\n",
    "    description[0] = \" \".join(description[0].split())\n",
    "    print(url, doi, title, pub_name, type_, description)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to extract head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text = root.find('{http://www.elsevier.com/xml/svapi/article/dtd}originalText')\n",
    "#print(originaltext)\n",
    "doc = original_text.find('{http://www.elsevier.com/xml/xocs/dtd}doc')\n",
    "#print(doc)\n",
    "serial_item = doc.find('{http://www.elsevier.com/xml/xocs/dtd}serial-item')\n",
    "#print(serial_item)\n",
    "\n",
    "keyword_list = []\n",
    "author_list = []\n",
    "if serial_item != None:\n",
    "    article = serial_item.find('{http://www.elsevier.com/xml/ja/dtd}article')\n",
    "    #print(article)\n",
    "    head = article.find('{http://www.elsevier.com/xml/ja/dtd}head')\n",
    "    #print(head)\n",
    "    author_group = head.find('{http://www.elsevier.com/xml/common/dtd}author-group')\n",
    "    #print(author_group)\n",
    "\n",
    "    keywords_ = head.find('{http://www.elsevier.com/xml/common/dtd}keywords')\n",
    "    #print(keywords_)\n",
    "\n",
    "    for author in author_group.findall('{http://www.elsevier.com/xml/common/dtd}author'):\n",
    "        name = author.find('{http://www.elsevier.com/xml/common/dtd}given-name').text\n",
    "        surname = author.find('{http://www.elsevier.com/xml/common/dtd}surname').text\n",
    "        author_list.append(name + ' ' + surname)\n",
    "        print('\\t')\n",
    "\n",
    "    for word in keywords_.itertext():\n",
    "        keyword_list.append(word)\n",
    "\n",
    "    keyword_list = \"\".join(keyword_list)\n",
    "    keyword_list = list(keyword_list.split())\n",
    "\n",
    "    print(keyword_list)\n",
    "    print(author_list)\n",
    "\n",
    "    \n",
    "else:\n",
    "    print(\"Full text for this paper doesn't exist\")\n",
    "\n",
    "d = dict(url = np.array(url), \n",
    "         doi = np.array(doi), \n",
    "         title = np.array(title), \n",
    "         pub_name = np.array(pub_name), \n",
    "         Type = np.array(type_), \n",
    "         abstract= np.array(description), \n",
    "         authors= np.array(author_list), \n",
    "         keyword =np.array(keyword_list))\n",
    "\n",
    "#Save it in a dataframe\n",
    "df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in d.items() ]))\n",
    "df.fillna('', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to extract body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = article.find('{http://www.elsevier.com/xml/ja/dtd}body')\n",
    "#print(body) #check\n",
    "sections = body.find('{http://www.elsevier.com/xml/common/dtd}sections')\n",
    "#print(sections) #check\n",
    "\n",
    "#lists for dataframe\n",
    "label_list = [] \n",
    "title_list = []\n",
    "para_list = []\n",
    "\n",
    "#A multiple iterative loop to iterate through every section, subsection, paragraphs and sentences\n",
    "#Same logic of root to next node to root to subsequent node is followed at every loop\n",
    "\n",
    "for section1 in sections.findall('{http://www.elsevier.com/xml/common/dtd}section'):\n",
    "    if section1.find('{http://www.elsevier.com/xml/common/dtd}label') != None:\n",
    "        label = section1.find('{http://www.elsevier.com/xml/common/dtd}label').text\n",
    "        label_list.append(label)\n",
    "        print(label)\n",
    "\n",
    "        section_title_list = []\n",
    "        section_title = section1.find('{http://www.elsevier.com/xml/common/dtd}section-title')\n",
    "        for sec in section_title.itertext():\n",
    "            section_title_list.append(sec)\n",
    "\n",
    "        section_title_list = \"\".join(section_title_list)\n",
    "        section_title_list = list(section_title_list.split()) \n",
    "        section_title_list = \" \".join(section_title_list)\n",
    "        title_list.append(section_title_list)\n",
    "        print(section_title_list)\n",
    "\n",
    "        total_para = []\n",
    "        \n",
    "        #Code to extract main text before entering the subsection\n",
    "        #paragraph = section1.find('{http://www.elsevier.com/xml/common/dtd}para')\n",
    "        for paragraph in section1.findall('{http://www.elsevier.com/xml/common/dtd}para'):\n",
    "            if paragraph != None:\n",
    "                #paragraph = paragraph.text\n",
    "                #print(paragraph)\n",
    "                #print('\\n')\n",
    "                paragraph1 = []\n",
    "                for p in paragraph.itertext():\n",
    "                    paragraph1.append(p)\n",
    "\n",
    "                paragraph1 = \"\".join(paragraph1)\n",
    "                paragraph1 = list(paragraph1.split()) \n",
    "                paragraph1 = \" \".join(paragraph1)\n",
    "                total_para.append(paragraph1)\n",
    "\n",
    "        total_para = \" \".join(total_para)\n",
    "        print(total_para)\n",
    "        para_list.append(total_para)\n",
    "        print('\\n')\n",
    "        \n",
    "        #Code to extract substection paragraphs\n",
    "        for section2 in section1.findall('{http://www.elsevier.com/xml/common/dtd}section'):\n",
    "            if section2.find('{http://www.elsevier.com/xml/common/dtd}label') !=None:\n",
    "                label = section2.find('{http://www.elsevier.com/xml/common/dtd}label').text\n",
    "                label_list.append(label)\n",
    "                print('sub-section ', label)\n",
    "\n",
    "                sub_section_title_list = []\n",
    "\n",
    "                sub_section_title = section2.find('{http://www.elsevier.com/xml/common/dtd}section-title')\n",
    "                for sub in sub_section_title.itertext():\n",
    "                    sub_section_title_list.append(sub)\n",
    "\n",
    "                sub_section_title_list = \"\".join(sub_section_title_list)\n",
    "                sub_section_title_list = list(sub_section_title_list.split()) \n",
    "                sub_section_title_list = \" \".join(sub_section_title_list)\n",
    "                title_list.append(sub_section_title_list)\n",
    "                #print('sub-section-title: ', sub_section_title_list)\n",
    "\n",
    "                #Code to extract multiple paragraphs under same subsection\n",
    "                para1 = []\n",
    "                for para in section2.itertext():\n",
    "                #findall('{http://www.elsevier.com/xml/common/dtd}para'):\n",
    "                    #paragraph = para.\n",
    "                    #for i in paragraph: \n",
    "                    para1.append(para)\n",
    "\n",
    "                para1 = \"\".join(para1)\n",
    "                para1 = list(para1.split()) \n",
    "                para1 = \" \".join(para1)\n",
    "                print(para1) \n",
    "                para_list.append(para1)\n",
    "                print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary to store all the values\n",
    "d = dict(url = np.array(url), \n",
    "         doi = np.array(doi), \n",
    "         title = np.array(title), \n",
    "         pub_name = np.array(pub_name), \n",
    "         Type = np.array(type_), \n",
    "         abstract= np.array(description), \n",
    "         authors= np.array(author_list), \n",
    "         keyword =np.array(keyword_list),\n",
    "         title_label = np.array(label_list),\n",
    "         titles = np.array(title_list),\n",
    "         text = np.array(para_list))\n",
    "\n",
    "df = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in d.items() ]))\n",
    "df.fillna('', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C://Users//swath//Downloads//paper_xml_parsed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the text to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict = {} #This will create a dictionary where we will store information about the searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in root.findall('{http://www.elsevier.com/xml/svapi/article/dtd}coredata'):\n",
    "    \n",
    "    url = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}url').text\n",
    "    doi = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}doi').text\n",
    "    title = entry.find('{http://purl.org/dc/elements/1.1/}title').text\n",
    "    pub_name = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}publicationName').text\n",
    "    type_ = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}aggregationType').text\n",
    "    description = entry.find('{http://purl.org/dc/elements/1.1/}description').text\n",
    "    print(url, doi, title, pub_name, type_, description)\n",
    "    print('\\n')\n",
    "    \n",
    "    #CHECK CODE\n",
    "    info_dict['URL'] = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}url').text\n",
    "    info_dict['DOI'] = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}doi').text\n",
    "    info_dict['Title'] = entry.find('{http://purl.org/dc/elements/1.1/}title').text\n",
    "    info_dict['Pub_Name'] = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}publicationName').text\n",
    "    info_dict['Type'] = entry.find('{http://prismstandard.org/namespaces/basic/2.0/}aggregationType').text\n",
    "    info_dict['Abstract'] = entry.find('{http://purl.org/dc/elements/1.1/}description').text\n",
    "    print(url, doi, title, pub_name, type_, description)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_text = root.find('{http://www.elsevier.com/xml/svapi/article/dtd}originalText')\n",
    "#print(originaltext)\n",
    "doc = original_text.find('{http://www.elsevier.com/xml/xocs/dtd}doc')\n",
    "#print(doc)\n",
    "serial_item = doc.find('{http://www.elsevier.com/xml/xocs/dtd}serial-item')\n",
    "#print(serial_item)\n",
    "article = serial_item.find('{http://www.elsevier.com/xml/ja/dtd}article')\n",
    "#print(article)\n",
    "\n",
    "head = article.find('{http://www.elsevier.com/xml/ja/dtd}head')\n",
    "#print(head)\n",
    "author_group = head.find('{http://www.elsevier.com/xml/common/dtd}author-group')\n",
    "#print(author_group)\n",
    "\n",
    "keywords_ = head.find('{http://www.elsevier.com/xml/common/dtd}keywords')\n",
    "#print(keywords_)\n",
    "full_name_list = []\n",
    "full_name_dict = {}\n",
    "for author in author_group.findall('{http://www.elsevier.com/xml/common/dtd}author'):\n",
    "    name = author.find('{http://www.elsevier.com/xml/common/dtd}given-name').text\n",
    "    surname = author.find('{http://www.elsevier.com/xml/common/dtd}surname').text\n",
    "    full_name_dict['Name'] = name + surname\n",
    "    full_name_list.append(full_name_dict)\n",
    "    \n",
    "keyword_list = []\n",
    "keyword_dict = {}\n",
    "\n",
    "for keyword in keywords_.findall('{http://www.elsevier.com/xml/common/dtd}keyword'):\n",
    "    keyword = keyword.find('{http://www.elsevier.com/xml/common/dtd}text').text\n",
    "    keyword_dict['Keywords'] = keyword\n",
    "    keyword_list.append(keyword_dict)\n",
    "    print(keyword_list)\n",
    "\n",
    "print(full_name_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is run in loop until all doi are exhaisted and stored in CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
